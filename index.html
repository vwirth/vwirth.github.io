<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Vanessa Wirth</title>

  <meta name="author" content="Vanessa Wirth">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  <link rel="stylesheet" href="./nfcalib/static/css/fontawesome.all.min.css">
  <script defer src="./nfcalib/static/js/fontawesome.all.min.js"></script>
</head>

<body>
  <table
    style="width:100%;max-width:1200px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:73%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Vanessa Wirth</name>
                  </p>
                  <p>I am a PhD candidate at the <a href="https://www.lgdv.tf.fau.de">Chair of Visual Computing</a>
                    (LGDV) at
                    <a href="https://www.fau.eu">FAU Erlangen-N√ºrnberg</a>,
                    supervised by Prof. Marc Stamminger. <br>
                    I am part of the CRC <a href="https://www.empkins.de/">EmpkinS</a>.
                  </p>
                  <p>
                    I work at the intersection of <b>computer vision, computer graphics, and machine learning</b>.
                    My research interests are focused on <b>static and dynamic reconstruction using multiple modalities,
                      in particular radar</b>.
                    Apart from theoretical
                    research, I strive to apply my work to real-world scenarios such as <b>medical applications</b>.
                  </p>
                  <p>
                    Before my Ph.D., I studied computer science at <a href="https://www.fau.eu">FAU
                      Erlangen-N√ºrnberg</a> and the <a href="https://www.idsia.ch/">IDSIA</a> lab (<a
                      href="https://people.idsia.ch//~juergen/deutsch.html">Prof. Dr.
                      J√ºrgen Schmidhuber</a>) at <a href="https://www.usi.ch/en">USI</a> in Lugano (Switzerland).
                    My master thesis was supervised by <a
                      href="http://www.niessnerlab.org/members/matthias_niessner/profile.html">Prof. Dr. Matthias
                      Nie√üner</a> at <a href="https://www.tum.de/en/">TU Munich</a>.
                  </p>
                  <p style="text-align:center">
                    <!-- <a href="mailto:vanessa.wirth@fau.de">Email</a> &nbsp/&nbsp -->
                    <a href="https://www.linkedin.com/in/vanessa-wirth-863402198/">LinkedIn</a> &nbsp/&nbsp
                    <a href="https://twitter.com/vwirth_">Twitter</a> &nbsp/&nbsp
                    <a href="https://github.com/vwirth/">Github</a> &nbsp/&nbsp
                    <!-- <a href="https://www.lgdv.tf.fau.de/person/vanessa-wirth/">Website@LGDV</a> &nbsp/&nbsp -->
                    <a
                      href="https://scholar.google.com/citations?hl=en&user=uTl2wGAAAAAJ&view_op=list_works&gmla=ABEO0YqYi56aNtfJLV1VP545Z9nq4paTxqHKnYZe-Pm6fktg6bUt3RlUY3NUyaZ9Xmve5-fcV2vl7qexZ_wfqUP5">Google
                      Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://www.researchgate.net/profile/Vanessa-Wirth-2">ResearchGate</a>
                    &nbsp/&nbsp
                    <a href="https://www.youtube.com/@vwirthyt/videos">Youtube</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/image.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/image_round.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <ul>
                    <li>[01/2025] &#127881; One paper accepted at IEEE Journal of Microwaves
                    </li>
                    <li>[10/2024] &#127881; I created a <a href="https://www.youtube.com/@vwirthyt/videos"><b>Youtube
                          channel</b></a> &#128249; for my oral presentations
                    </li>
                    <li>[08/2024] &#127881; One paper accepted at IEEE Journal of Microwaves
                    </li>
                    <li>[07/2024] &#127881; Two papers accepted (IROS, EuRAD)
                    </li>
                    <li>[02/2024] &#127881; Our paper "ShaRPy" won the <b><a
                          href="https://digitalrheumatology.org/winner-2024-digital-rheumatology-research-award/">Digital
                          Rheumatology Award</a></b> for the most innovative publication in the field of digital
                      rheumatology in the last two years
                    </li>
                    <li>[10/2024] &#127881; Our paper "A Realistic Radar Ray Tracing Simulator for Hand Pose Imaging"
                      won the <b><a href="https://www.lhft.eei.fau.de/en/archive/8529">Young Engineer Price</a></b>
                    </li>
                    <li>[10/2023] &#127881; Our abstract pitch about "ShaRPy" at the IEEE BHI won the <b><a
                          href="https://www.empkins.de/2023/10/25/empkins-research-awarded-at-ieee-bhi-conference/">Best
                          Poster Award</a></b></li>
                    <li>[07/2023] &#127881; Two papers accepted (ICCVW, EuRAD)
                    </li>
                  </ul>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    I'm interested in computer vision, computer graphics, machine learning, and novel sensor concepts.
                    My primary application focus is within the medical domain.
                    Representative papers are <span class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/mm2fskteaser.jpg' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle>MM-2FSK: Multimodal Frequency Shift Keying for Ultra-Efficient and Robust High-Resolution
                    MIMO Radar Imaging
                  </papertitle>
                  <br>
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/braeunig-johanna-m-sc">Johanna Br√§unig</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/prof-dr-ing-martin-vossiek">Martin Vossiek</a>,
                  <a href="https://weyri.ch/">Tim Weyrich</a>,
                  <a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger</a>

                  <p></p>
                  <em>arXiv</em>, 2025 <br>
                  <a href="https://arxiv.org/abs/2511.01405">[arXiv]</a>
                  <p></p>
                  <p>
                    We improve current limitations of high-speed radar-based depth estimation through multimodal sensor
                    fusion.
                  </p>
                </td>
              </tr>
              <tr bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/maroonteaser.jpg' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle>MAROON: A Dataset for the Joint Characterization of Near-Field High-Resolution
                    Radio-Frequency and Optical Depth Imaging Techniques
                  </papertitle>
                  <br>
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/braeunig-johanna-m-sc">Johanna Br√§unig</a>,
                  <a href="https://www.lgdv.tf.fau.de/person/2068/">Nikolai Hofmann</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/prof-dr-ing-martin-vossiek">Martin Vossiek</a>,
                  <a href="https://weyri.ch/">Tim Weyrich</a>,
                  <a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger</a>

                  <p></p>
                  <em>arXiv</em>, 2025 <br>
                  <!-- <a href="https://vwirth.github.io/maroon">[Project Page]</a> -->
                  <a href="./maroon">[Project Page]</a>
                  <a href="https://arxiv.org/abs/2411.00527">[arXiv]</a>
                  <p></p>
                  <p>
                    We present the first multimodal dataset that includes imaging radars, jointly calibrated with three
                    different optical depth cameras, and a common ground truth.
                    Using this dataset, we jointly investigate sensor characteristics, in particular those of imaging
                    radars.
                    We also show two example applications of our dataset.
                  </p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/inversematerial.jpg' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle>Inverse Rendering of Near-Field mmWave MIMO Radar for Material Reconstruction
                  </papertitle>
                  <br>
                  <a href="https://www.lgdv.tf.fau.de/person/2068/">Nikolai Hofmann</a>,
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/braeunig-johanna-m-sc">Johanna Br√§unig</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/dipl-ing-ingrid-ullmann">Ingrid Ullmann</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/prof-dr-ing-martin-vossiek">Martin Vossiek</a>,
                  <a href="https://weyri.ch/">Tim Weyrich</a>,
                  <a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger</a>

                  <p></p>
                  <em>IEEE Journal of Microwaves</em>, 2025 <br>
                  <a href="https://github.com/nihofm/inverse-radar-rendering">[Code]</a>
                  <a href="https://ieeexplore.ieee.org/document/10892639">[Paper]</a>
                  <p></p>
                  <p>
                    We present a novel approach to inverse rendering for near-field MIMO radar systems, aimed at
                    reconstructing material properties such as surface roughness, dielectric constants, and conductivity
                    from radar and ground-truth mesh data.
                  </p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/velocityteaser.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle>A Radar-Based Concept for Simultaneous High-Resolution Imaging and Pixel-Wise Velocity
                    Analysis for Tracking Human Motion
                  </papertitle>
                  <br>
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/braeunig-johanna-m-sc">Johanna Br√§unig</a>,
                  <a href="https://www.ltd.tf.fau.de/person/simon-heinrich/">Simon Heinrich</a>,
                  <a href="https://www.ltd.tf.fau.de/ltd/institute/team/coppers-birte/">Birte Coppers</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/kammel-christoph-m-sc">Christoph Kammel</a>,
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger</a>,
                  <a href="https://www.ltd.tf.fau.de/person/sigrid-leyendecker/">Sigrid Leyendecker</a>,
                  <a href="https://www.medizin3.uk-erlangen.de/forschung/arbeitsgruppen/ag-dr-a-m-liphardt/">Anna-Maria
                    Liphardt</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/dipl-ing-ingrid-ullmann">Ingrid Ullmann</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/prof-dr-ing-martin-vossiek">Martin Vossiek</a>
                  <p></p>
                  <em>IEEE Journal of Microwaves</em>, 2024 <br>
                  <a href="https://ieeexplore.ieee.org/document/10706625/authors">[Paper]</a>
                  <p></p>
                  <p>
                    We propose a novel concept for high-resolution MIMO radars to track the pixel-wise velocity
                    alongside the depth of human motions.
                  </p>
                </td>
              </tr>
              <tr onmouseout="mfcalib_stop()" onmouseover="nfcalib_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nfcalib_image' style="width:100%"><video width=100% height=100%
                        style="object-fit:fill" muted autoplay loop>
                        <source src="images/nfcalib.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/nfcalibteaser.png' width="100%">
                  </div>
                  <script type="text/javascript">
                    function nfcalib_start() {
                      document.getElementById('nfcalib_image').style.opacity = "0";
                    }

                    function mfcalib_stop() {
                      document.getElementById('nfcalib_image').style.opacity = "1";
                    }
                    mfcalib_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle>Automatic Spatial Calibration of Near-Field MIMO Radar With Respect to Optical Depth
                    Sensors
                  </papertitle>
                  <br>
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/braeunig-johanna-m-sc">Johanna Br√§unig</a>,
                  <a>Danti Khouri</a>,
                  <a>Florian Gutsche</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/prof-dr-ing-martin-vossiek">Martin Vossiek</a>,
                  <a href="https://weyri.ch/">Tim Weyrich*</a>,
                  <a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger*</a>
                  <p></p>
                  <em>IROS <a style="color:red"><b>(Oral)</b></a></em>, 2024 <br>
                  <a href="https://vwirth.github.io/nfcalib">[Project Page]</a>
                  <a href="https://ieeexplore.ieee.org/document/10801705">[Paper]</a>
                  <a href="https://arxiv.org/abs/2403.10981">[arXiv]</a>
                  <p></p>
                  <p>
                    We propose a spatial calibration method for high-resolution radars
                    that operate in the near-field, in conjunction with RGB-D cameras.
                    Our calibration enables close-range sensor fusion applications with millimeter precision.
                  </p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/3fskteaser.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle>An Efficient yet High-Performance Method for Precise Radar-Based Imaging of Human Hand
                    Poses
                  </papertitle>
                  <br>
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/braeunig-johanna-m-sc">Johanna Br√§unig</a>,
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/dipl-ing-ingrid-ullmann">Ingrid Ullmann</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/prof-dr-ing-martin-vossiek">Martin Vossiek</a>
                  <p></p>
                  <em>EuRAD</em>, 2024 <br>
                  <a href="https://ieeexplore.ieee.org/abstract/document/10734919">[Paper]</a>
                  <a href="https://arxiv.org/abs/2406.13464">[arXiv]</a>
                  <p></p>
                  <p>
                    We improve our <a href="https://ieeexplore.ieee.org/document/10233087">previous work</a>
                    for SOTA Radar reconstruction by utilizing three carrier frequencies.
                    The proposed method enables real-time reconstructions with improved quality.
                  </p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/hand_simulation.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle>A Realistic Radar Ray Tracing Simulator for Hand Pose Imaging
                  </papertitle>
                  <br>
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/braeunig-johanna-m-sc">Johanna Br√§unig</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/schuessler-christian-m-sc">Christian
                    Sch√ºssler</a>,
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/dipl-ing-ingrid-ullmann">Ingrid Ullmann</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/prof-dr-ing-martin-vossiek">Martin Vossiek</a>
                  <p></p>
                  <em>EuRAD <a style="color:red"><b>(Young Engineer Price)</b></a></em>, 2023 <br>
                  <a href="https://ieeexplore.ieee.org/document/10289483">[Paper]</a>
                  <a href="https://arxiv.org/abs/2307.15412">[arXiv]</a>
                  <p></p>
                  <p>
                    We apply different material parameters to simulate the radar signal of a human hand using a Ray
                    Tracing simulator. In this way, we can show that it is possible to generate very realistic
                    simulations of radar data.
                  </p>
                </td>
              </tr>
              <tr onmouseout="sharpy_stop()" onmouseover="sharpy_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='sharpy_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/sharpy.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/sharpy.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function sharpy_start() {
                      document.getElementById('sharpy_image').style.opacity = "0";
                    }

                    function sharpy_stop() {
                      document.getElementById('sharpy_image').style.opacity = "1";
                    }
                    sharpy_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle>ShaRPy: Shape Reconstruction and Hand Pose Estimation from RGB-D with Uncertainty
                  </papertitle>
                  <br>
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.medizin3.uk-erlangen.de/forschung/arbeitsgruppen/ag-dr-a-m-liphardt/">Anna-Maria
                    Liphardt</a>,
                  <a href="https://www.ltd.tf.fau.de/ltd/institute/team/coppers-birte/">Birte Coppers</a>,
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/braeunig-johanna-m-sc">Johanna Br√§unig</a>,
                  <a href="https://www.ltd.tf.fau.de/person/simon-heinrich/">Simon Heinrich</a>,
                  <a href="https://www.ltd.tf.fau.de/person/sigrid-leyendecker/">Sigrid Leyendecker</a>,
                  <a
                    href="https://www.medizin3.uk-erlangen.de/forschung/arbeitsgruppen/ag-pd-dr-a-kleyer-und-pd-dr-d-simon/">Arnd
                    Kleyer</a>,
                  <a href="https://www.fau.eu/fau/organisation-and-committees/executive-board/prof-dr-georg-schett/">Georg
                    Schett</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/prof-dr-ing-martin-vossiek">Martin Vossiek</a>,
                  <a href="https://eggerbernhard.ch/">Bernhard Egger</a>,
                  <a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger</a>
                  <p></p>
                  <em>ICCVW <a style="color:red"><b>(Oral)</b></a></em>, 2023 <br>
                  <em><b>Winner of the <a style="color:red"
                        href="https://digitalrheumatology.org/winner-2024-digital-rheumatology-research-award/">Digital
                        Rheumatology Award 2024</a></b> <br>
                    <a href="https://vwirth.github.io/sharpy">[Project Page]</a>
                    <a
                      href="https://openaccess.thecvf.com/content/ICCV2023W/CVAMD/html/Wirth_ShaRPy_Shape_Reconstruction_and_Hand_Pose_Estimation_from_RGB-D_with_ICCVW_2023_paper.html">[Paper]</a>
                    <a href="https://arxiv.org/abs/2303.10042">[arXiv]</a>
                    <a href="https://github.com/vwirth/sharpy">[Code]</a>
                    <p></p>
                    <p>
                      We propose a novel hand pose and shape tracking pipeline that calculates the uncertainty, which
                      remains in the parameter estimates. We apply this pipeline to hand function assessments in the
                      medical domain.
                    </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2fsk.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle>An Ulta-Efficient Approach for High-Resolution MIMO Radar Imaging of Human Hand Poses
                  </papertitle>
                  <br>
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/braeunig-johanna-m-sc">Johanna Br√§unig</a>,
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/kammel-christoph-m-sc">Christoph Kammel</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/schuessler-christian-m-sc">Christian
                    Sch√ºssler</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/dipl-ing-ingrid-ullmann">Ingrid Ullmann</a>,
                  <a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/prof-dr-ing-martin-vossiek">Martin Vossiek</a>
                  <p></p>
                  <em>IEEE Transactions on Radar Systems</em>, 2023 <br>
                  <a href="https://ieeexplore.ieee.org/document/10233087">[Paper]</a>
                  <p></p>
                  <p>
                    We improve the performance of current SOTA Radar Imaging methods by the approximation of
                    possible surface locations and subsequent refinement operations.
                    Our method works with only two carrier frequencies.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/synthetic_annotations.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle>Achieving Efficient and Realistic Full-Radar Simulations and Automatic Data Annotation by
                    Exploiting Ray Meta Data from a Radar Ray Tracing Simulator
                  </papertitle>
                  <br>
                  <a href="https://www.lhft.eei.fau.de/archive/person/schuessler-christian-m-sc">Christian
                    Sch√ºssler</a>,
                  <a href="https://www.lhft.eei.fau.de/en/archive/person/marcel-hoffmann-m-sc">Marcel Hoffmann</a>,
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.mad.tf.fau.de/person/bjoern-eskofier/">Bj√∂rn Eskofier</a>,
                  <a href="https://reality.tf.fau.de/weyrich.html">Tim Weyrich</a>,
                  <a href="https://www.lgdv.tf.fau.de/person/marc-stamminger/">Marc Stamminger</a>,
                  <a href="https://www.lhft.eei.fau.de/archive/person/prof-dr-ing-martin-vossiek">Martin Vossiek</a>
                  <p></p>
                  <em>IEEE RadarConf</em>, 2023 <br>
                  <a href="https://arxiv.org/abs/2305.14176">[arXiv]</a>
                  <p></p>
                  <p>
                    We build on a realistic Range-Doppler radar signal simulator to automatically generate accurate
                    ground-truth annotations for synthetic data.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Leisure Time Research</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="aua_stop()" onmouseover="aua_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='aua_image'>
                      <img src='images/aua_after.png' width="160">
                    </div>
                    <img src='images/aua_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function aua_start() {
                      document.getElementById('aua_image').style.opacity = "1";
                    }

                    function aua_stop() {
                      document.getElementById('aua_image').style.opacity = "0";
                    }
                    aua_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Author-Unification: Name-, Institution-, and Career-Sharing Co-authors
                  </papertitle>
                  <br>
                  <strong>Vanessa Wirth</strong>,
                  <a href="https://www.lte.tf.fau.eu/person/vanessa-wirth/">Vanessa Wirth</a>
                  <br>
                  <p></p>
                  <em>SIGBOVIK</em>, 2023 <br>
                  <a href="data/sigbovik23_aua.pdf">[Link]</a>
                  <p></p>
                  <p>
                    We investigate the phenomenon of Author-UnificAtion (AUA), which describes the high structural
                    similarity of two co-authoring engineers that share the same forename, surname, institution, and
                    academic career without being related by blood.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    The template of this website can be stolen from Jon Barron's <a
                      href="https://github.com/jonbarron/jonbarron_website">source
                      code</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>